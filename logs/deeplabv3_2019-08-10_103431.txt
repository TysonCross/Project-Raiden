Checking sequences...
Loaded metadata from cache...
Loaded datastores from cache...
Per-label pixel distribution:
       <strong>Name</strong>        <strong>PixelCount</strong>    <strong>ImagePixelCount</strong>
    <strong>___________</strong>    <strong>__________</strong>    <strong>_______________</strong>
    'lightning'    4.7808e+06      1.3836e+09   
    'stroke'       6.6153e+05      2.6935e+07   
    'sky'          8.6656e+08      1.6498e+09   
    'cloud'        6.0089e+08      1.1435e+09   
    'ground'       1.7668e+08      1.6499e+09   
Using training/validation split from cache...
Training images: 20140 
Validation images: 5035 
Testing images: 4420 
Setting up Network...
Network created
Setting up Training...
options = 
  <a href="matlab:helpPopup nnet.cnn.TrainingOptionsSGDM" style="font-weight:bold">TrainingOptionsSGDM</a> with properties:

                     Momentum: 9.0000e-01
             InitialLearnRate: 1.0000e-03
    LearnRateScheduleSettings: [1×1 struct]
             L2Regularization: 5.0000e-03
      GradientThresholdMethod: 'l2norm'
            GradientThreshold: 10
                    MaxEpochs: 50
                MiniBatchSize: 100
                      Verbose: 1
             VerboseFrequency: 50
               ValidationData: [1×1 pixelLabelImageDatastore]
          ValidationFrequency: 50
           ValidationPatience: 8
                      Shuffle: 'every-epoch'
               CheckpointPath: '/home/tyson/Raiden/networks/checkpoints'
         ExecutionEnvironment: 'parallel'
                   WorkerLoad: []
                    OutputFcn: []
                        Plots: 'training-progress'
               SequenceLength: 'longest'
         SequencePaddingValue: 0
         DispatchInBackground: 0
Beginning training...
[Warning: Unable to assign workers with indices [2 3 4 5 6 7 8 9 10 11 12 13 14 15 16] in the parallel pool their own GPUs, so these workers will be unused. When
configuring the cluster, ensure only one worker per GPU is running on each host.] 
Training across multiple GPUs.
|======================================================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |   Accuracy   |     Loss     |     Loss     |      Rate       |
|======================================================================================================================|
Lab  1: 
  Warning: While copying object of class 'gpuArray':
  'Out of memory on device. To view more detail about available memory on the GPU, use 'gpuDevice()'. If the problem persists, reset the GPU by calling 'gpuDevice(1)'.'
  > In nnet.internal.cnn.DAGNetwork/forwardPropagationWithMemory (line 330)
    In nnet.internal.cnn.DAGNetwork/computeGradientsForTraining (line 682)
    In nnet.internal.cnn.Trainer/computeGradients (line 196)
    In nnet.internal.cnn.ParallelTrainer/computeGradientsInBatches (line 408)
    In nnet.internal.cnn.ParallelTrainer/trainLocal (line 210)
    In nnet.internal.cnn.ParallelTrainer>@(varargin)this.trainLocal(varargin{:}) (line 94)
    In nnet.internal.cnn.RemoteDispatchAdapter/compute (line 65)
    In spmdlang.remoteBlockExecution (line 50)
  Warning: While copying object of class 'gpuArray':
  'Out of memory on device. To view more detail about available memory on the GPU, use 'gpuDevice()'. If the problem persists, reset the GPU by calling 'gpuDevice(1)'.'
  > In nnet.internal.cnn.DAGNetwork/forwardPropagationWithMemory (line 254)
    In nnet.internal.cnn.DAGNetwork/computeGradientsForTraining (line 682)
    In nnet.internal.cnn.Trainer/computeGradients (line 196)
    In nnet.internal.cnn.ParallelTrainer/computeGradientsInBatches (line 408)
    In nnet.internal.cnn.ParallelTrainer/trainLocal (line 210)
    In nnet.internal.cnn.ParallelTrainer>@(varargin)this.trainLocal(varargin{:}) (line 94)
    In nnet.internal.cnn.RemoteDispatchAdapter/compute (line 65)
    In spmdlang.remoteBlockExecution (line 50)
{Error using <a href="matlab:matlab.internal.language.introspective.errorDocCallback('trainNetwork', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/trainNetwork.m', 165)" style="font-weight:bold">trainNetwork</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/trainNetwork.m',165,0)">line 165</a>)
The data no longer exists on the device.
Error in <a href="matlab:matlab.internal.language.introspective.errorDocCallback('CNN_Segmentation_Train_and_Evaluate', '/home/tyson/Dropbox/Academic/4th Year/ELEN4012/Raiden/matlab/CNN_Segmentation_Train_and_Evaluate.m', 575)" style="font-weight:bold">CNN_Segmentation_Train_and_Evaluate</a> (<a href="matlab: opentoline('/home/tyson/Dropbox/Academic/4th Year/ELEN4012/Raiden/matlab/CNN_Segmentation_Train_and_Evaluate.m',575,0)">line 575</a>)
    [net, networkStatus.info] = trainNetwork(pximds, net, options);
Caused by:
    Error using <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.ParallelTrainer/train', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/ParallelTrainer.m', 95)" style="font-weight:bold">nnet.internal.cnn.ParallelTrainer/train</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/ParallelTrainer.m',95,0)">line 95</a>)
    Error detected on worker 1.
        Error using <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.layer.util.ReLUGPUStrategy/forward', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/+layer/+util/ReLUGPUStrategy.m', 8)" style="font-weight:bold">nnet.internal.cnn.layer.util.ReLUGPUStrategy/forward</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/+layer/+util/ReLUGPUStrategy.m',8,0)">line 8</a>)
        The data no longer exists on the device.} 
