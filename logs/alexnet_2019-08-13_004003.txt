Converting Data...
Starting parallel pool (parpool) using the 'local' profile ...
Connected to the parallel pool (number of workers: 16).
Resizing images and labels, converting to categorical label form...
Data converted successfully
Metadata cached
Partitioning test and training Data...
Counting per-label pixel distribution...
       <strong>Name</strong>        <strong>PixelCount</strong>    <strong>ImagePixelCount</strong>
    <strong>___________</strong>    <strong>__________</strong>    <strong>_______________</strong>
    'lightning'    3.7230e+06      1.0820e+09   
    'stroke'       7.0510e+05      2.0199e+07   
    'sky'          6.8472e+08      1.2963e+09   
    'cloud'        4.6558e+08      8.8841e+08   
    'ground'       1.4139e+08      1.2964e+09   
Datastores cached
Splitting training/validation data...
Training images: 20126 
Validation images: 5032 
Testing images: 4437 
Data cached
Setting up Network...
Network created
Setting up Training...
options = 
  <a href="matlab:helpPopup nnet.cnn.TrainingOptionsSGDM" style="font-weight:bold">TrainingOptionsSGDM</a> with properties:

                     Momentum: 9.0000e-01
             InitialLearnRate: 1.0000e-03
    LearnRateScheduleSettings: [1×1 struct]
             L2Regularization: 5.0000e-03
      GradientThresholdMethod: 'l2norm'
            GradientThreshold: 10
                    MaxEpochs: 50
                MiniBatchSize: 100
                      Verbose: 1
             VerboseFrequency: 50
               ValidationData: [1×1 pixelLabelImageDatastore]
          ValidationFrequency: 50
           ValidationPatience: 6
                      Shuffle: 'every-epoch'
               CheckpointPath: '/home/tyson/Raiden/networks/checkpoints'
         ExecutionEnvironment: 'auto'
                   WorkerLoad: []
                    OutputFcn: []
                        Plots: 'training-progress'
               SequenceLength: 'longest'
         SequencePaddingValue: 0
         DispatchInBackground: 0
Beginning training...
Training on single GPU.
Initializing input data normalization.
|======================================================================================================================|
|  Epoch  |  Iteration  |  Time Elapsed  |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  |  Base Learning  |
|         |             |   (hh:mm:ss)   |   Accuracy   |   Accuracy   |     Loss     |     Loss     |      Rate       |
|======================================================================================================================|
|       1 |           1 |       00:03:30 |       19.96% |       20.38% |       1.6099 |       1.6096 |          0.0010 |
|       1 |          50 |       00:07:49 |       35.59% |       34.45% |       1.5810 |       1.5917 |          0.0010 |
|       1 |         100 |       00:12:01 |       40.69% |       42.73% |       1.5460 |       1.5744 |          0.0010 |
|       1 |         150 |       00:16:15 |       40.43% |       47.97% |       1.5217 |       1.5615 |          0.0010 |
|       1 |         200 |       00:20:29 |       44.92% |       49.00% |       1.4933 |       1.5514 |          0.0010 |
|       2 |         250 |       00:24:48 |       47.62% |       50.90% |       1.4767 |       1.5438 |          0.0010 |
|       2 |         300 |       00:29:03 |       44.11% |       51.43% |       1.4706 |       1.5379 |          0.0010 |
|       2 |         350 |       00:33:16 |       45.05% |       51.83% |       1.4686 |       1.5334 |          0.0010 |
|       2 |         400 |       00:37:31 |       49.30% |       52.37% |       1.4363 |       1.5300 |          0.0010 |
|       3 |         450 |       00:41:50 |       48.86% |       52.39% |       1.4315 |       1.5275 |          0.0010 |
|       3 |         500 |       00:46:05 |       44.03% |       52.26% |       1.4528 |       1.5257 |          0.0010 |
|       3 |         550 |       00:50:19 |       45.76% |       52.28% |       1.4440 |       1.5243 |          0.0010 |
|       3 |         600 |       00:54:32 |       45.90% |       52.31% |       1.4298 |       1.5230 |          0.0010 |
|       4 |         650 |       00:58:52 |       45.95% |       52.06% |       1.3925 |       1.5222 |          0.0010 |
|       4 |         700 |       01:03:05 |       47.05% |       51.74% |       1.4137 |       1.5214 |          0.0010 |
|       4 |         750 |       01:07:18 |       46.74% |       51.13% |       1.3979 |       1.5206 |          0.0010 |
|       4 |         800 |       01:11:29 |       45.59% |       50.79% |       1.3881 |       1.5198 |          0.0010 |
|       5 |         850 |       01:15:48 |       43.83% |       49.47% |       1.4258 |       1.5192 |          0.0010 |
|       5 |         900 |       01:20:05 |       40.77% |       48.70% |       1.4081 |       1.5178 |          0.0010 |
{Operation terminated by user during <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.DAGNetwork>@()efficientBackProp(i)', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/DAGNetwork.m', 797)" style="font-weight:bold">nnet.internal.cnn.DAGNetwork>@()efficientBackProp(i)</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/DAGNetwork.m',797,0)">line 797</a>)

In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.util.executeWithStagedGPUOOMRecovery', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/+util/executeWithStagedGPUOOMRecovery.m', 11)" style="font-weight:bold">nnet.internal.cnn.util.executeWithStagedGPUOOMRecovery</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/+util/executeWithStagedGPUOOMRecovery.m',11,0)">line 11</a>)
        [ varargout{1:nOutputs} ] = computeFun();
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.DAGNetwork>iExecuteWithStagedGPUOOMRecovery', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/DAGNetwork.m', 1473)" style="font-weight:bold">nnet.internal.cnn.DAGNetwork>iExecuteWithStagedGPUOOMRecovery</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/DAGNetwork.m',1473,0)">line 1473</a>)
[varargout{1:nargout}] = nnet.internal.cnn.util.executeWithStagedGPUOOMRecovery(varargin{:});
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.DAGNetwork/computeGradientsForTraining', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/DAGNetwork.m', 796)" style="font-weight:bold">nnet.internal.cnn.DAGNetwork/computeGradientsForTraining</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/DAGNetwork.m',796,0)">line 796</a>)
                    theseGradients = iExecuteWithStagedGPUOOMRecovery( ...
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.Trainer/computeGradients', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/Trainer.m', 196)" style="font-weight:bold">nnet.internal.cnn.Trainer/computeGradients</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/Trainer.m',196,0)">line 196</a>)
            [gradients, predictions, states] = net.computeGradientsForTraining(X, Y, needsStatefulTraining,
            propagateState);
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('nnet.internal.cnn.Trainer/train', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/Trainer.m', 115)" style="font-weight:bold">nnet.internal.cnn.Trainer/train</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/+nnet/+internal/+cnn/Trainer.m',115,0)">line 115</a>)
                    [gradients, predictions, states] = this.computeGradients(net, X, response,
                    needsStatefulTraining, propagateState);
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('trainNetwork>doTrainNetwork', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/trainNetwork.m', 234)" style="font-weight:bold">trainNetwork>doTrainNetwork</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/trainNetwork.m',234,0)">line 234</a>)
trainedNet = trainer.train(trainedNet, trainingDispatcher);
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('trainNetwork', '/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/trainNetwork.m', 163)" style="font-weight:bold">trainNetwork</a> (<a href="matlab: opentoline('/usr/local/MATLAB/R2019a/toolbox/nnet/cnn/trainNetwork.m',163,0)">line 163</a>)
    [trainedNet, info] = doTrainNetwork(layersOrGraph, opts, X, Y);
In <a href="matlab:matlab.internal.language.introspective.errorDocCallback('CNN_Segmentation_Train_and_Evaluate', '/home/tyson/Dropbox/Academic/4th Year/ELEN4012/Raiden/matlab/CNN_Segmentation_Train_and_Evaluate.m', 576)" style="font-weight:bold">CNN_Segmentation_Train_and_Evaluate</a> (<a href="matlab: opentoline('/home/tyson/Dropbox/Academic/4th Year/ELEN4012/Raiden/matlab/CNN_Segmentation_Train_and_Evaluate.m',576,0)">line 576</a>)
    disp("Evaluating network performance");} 
